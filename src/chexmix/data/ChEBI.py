import logging
import os

import numpy as np
import pandas as pd

import chexmix.utils as utils
from chexmix.env import data_path

logger = logging.getLogger(__name__)

CHEBI_PATH = os.path.join(data_path, 'chebi/Flat_file_tab_delimited')

ALL_FILES = ['chebiId_inchi.tsv',           # merged
             'database_accession.tsv',      # merged
             'compounds.tsv.gz',            # merged
             'default_structures.tsv',      # merged
             'names.tsv.gz',                # merged
             'structures.csv.gz',           # merged
             'autogenerated_structures.tsv',    # merged
             'compound_origins.tsv',        # merged, but ignored non-existent
             'vertice.tsv',                 # merged
             'relation.tsv',                # merged in 'ontology_relations'
             'ontology.tsv',
             'chemical_data.tsv',           # merged
             'chebi_uniprot.zip',
             'reference.tsv.gz',            # merged
             'comments.tsv'                 # merged
             ]


def inject_lists_(target, source, target_field, source_field, copy_fields):
    """inject elements in 'source' list into target_field of 'target' dict identified by source_field"""
    for source_elem in source:
        target_id = source_elem[source_field]
        target_elem = target[target_id]
        if target_field not in target_elem:
            target_elem[target_field] = []
        target_elem[target_field].append({k: v for k, v in source_elem.items() if k in copy_fields})

    return target


def apply_each_(target, source, to, on, func):
    """apply a `func` on each element of source and store the result in target"""
    for source_elem in source:
        target_id = source_elem[on]
        if target_id not in target:
            logger.debug(f'target {target_id} does not exist for {to}.')
            continue
        target_elem = target[target_id]
        target_elem[to] = func(target_elem, source_elem)
    return target


def remove_none_vals(dt):
    return {k: (v if not isinstance(v, np.int64) else int(v)) for k, v in dt.items() if not pd.isnull(v)}


def to_record_dict_(df, by):
    """convert dataframe to record dict"""
    return {x[by]: remove_none_vals(x) for x in df.to_dict(orient='records')}


def add_ancestors_(compounds_map, compound):
    """adds field ANECESTORS and returns it"""
    if 'ANCESTORS' in compound:
        return compound['ANCESTORS']

    ancestors = []
    for p in compound.get('PARENTS', []):
        ancestors += [p] + add_ancestors_(compounds_map, compounds_map[p])

    compound['ANCESTORS'] = sorted(set(ancestors))
    return compound['ANCESTORS']


def load_from_tsv_2():
    all_files = [os.path.join(CHEBI_PATH, x) for x in ['compounds.tsv.gz', 'compound_origins.tsv']]

    chebi = {utils.basename(fname):
             pd.read_csv(fname, encoding='ISO-8859-1', engine='python',
                         sep=r'\t+\s*' if 'csv' not in fname else ',',
                         header=0 if 'uniprot' not in fname else None,
                         dtype={'PARENT_ID': 'Int64', 'COMPOUND_ID': 'Int64'})
             for fname in all_files}

    return chebi


def load_from_tsv():
    all_files = [os.path.join(CHEBI_PATH, x) for x in ALL_FILES]

    chebi = {utils.basename(fname):
             pd.read_csv(fname, encoding='ISO-8859-1', engine='python',
                         sep=r'\t+\s*' if 'csv' not in fname else ',',
                         header=0 if 'uniprot' not in fname else None,
                         dtype={'PARENT_ID': 'Int64',
                                'COMPOUND_ID': 'Int64'})
             for fname in all_files}

    compounds = to_record_dict_(chebi['compounds'], 'ID')

    # inject comments
    inject_lists_(compounds,
                  chebi['comments'].to_dict('records'),
                  'COMMENTS',
                  'COMPOUND_ID',
                  ['TEXT', 'CREATED_ON', 'DATATYPE', 'DATATYPE_ID'])

    # inject structures
    structures = to_record_dict_(chebi['structures'], 'ID')
    apply_each_(structures,
                chebi['autogenerated_structures'].to_dict('records'),
                'AUTOGEN',
                'STRUCTURE_ID',
                lambda t, s: True)
    apply_each_(structures,
                chebi['default_structures'].to_dict('records'),
                'DEFAULT',
                'STRUCTURE_ID',
                lambda t, s: True)
    inject_lists_(compounds,
                  structures.values(),
                  'STRUCTURES',
                  'COMPOUND_ID',
                  ['STRUCTURE', 'TYPE', 'DIMENSION', 'AUTOGEN', 'DEFAULT'])

    # inject chemical_data
    inject_lists_(compounds,
                  [remove_none_vals(x) for x in chebi['chemical_data'].to_dict('records')],
                  'CHEMICAL_RECORDS',
                  'COMPOUND_ID',
                  ['CHEMICAL_DATA', 'SOURCE', 'TYPE'])

    # inject names
    inject_lists_(compounds,
                  [remove_none_vals(x) for x in chebi['names'].to_dict('records')],
                  'NAMES',
                  'COMPOUND_ID',
                  ['ADAPTED', 'NAME', 'SOURCE', 'TYPE'])

    # inject InChI
    apply_each_(compounds,
                [remove_none_vals(x) for x in chebi['chebiId_inchi'].to_dict('records')],
                'InChI',
                'CHEBI_ID',
                lambda t, s: s['InChI'])

    # inject reference
    # Note that reference is sometimes too big. e.g. CHEBI:4056
    inject_lists_(compounds,
                  [remove_none_vals(x) for x in chebi['reference'].to_dict('records')],
                  'REFERENCES',
                  'COMPOUND_ID',
                  ['REFERENCE', 'REFERENCE_DB_NAME', 'REFERENCE_NAME', 'LOCATION_IN_REF'])

    # inject database_accession
    inject_lists_(compounds,
                  [remove_none_vals(x) for x in chebi['database_accession'].to_dict('records')],
                  'DATABASE_ACCESSIONS',
                  'COMPOUND_ID',
                  ['SOURCE', 'TYPE', 'ACCESSION_NUMBER'])

    # inject origins
    origins = chebi['compound_origins']
    # some origin info do not have corresponding compound id of which compounds we will ignore
    origins = origins[~origins['COMPOUND_ID'].isnull()].copy()
    origins['COMPOUND_ID'] = origins.COMPOUND_ID.apply(int)
    inject_lists_(compounds,
                  [remove_none_vals(x) for x in origins.to_dict('records')],
                  'ORIGINS',
                  'COMPOUND_ID',
                  ['SPECIES_TEXT', 'SPECIES_ACCESSION', 'COMPONENT_TEXT',
                   'COMPONENT_ACCESSION', 'STRAIN_TEXT',
                   'STRAIN_ACCESSION', 'SOURCE_TYPE', 'SOURCE_ACCESSION', 'COMMENTS'])

    # inject uniprot
    # chebi_uniprot has newer compounds
    chebi['chebi_uniprot'].columns = ['COMPOUND_ID', 'UNIPROT', 'UNIPROT_RAW']
    apply_each_(compounds,
                chebi['chebi_uniprot'].to_dict('records'),
                'UNIPROT',
                'COMPOUND_ID',
                lambda t, s: s['UNIPROT'])
    apply_each_(compounds,
                chebi['chebi_uniprot'].to_dict('records'),
                'UNIPROT_RAW',
                'COMPOUND_ID',
                lambda t, s: s['UNIPROT_RAW'])

    # process ontology
    apply_each_(compounds,
                chebi['vertice'].to_dict('records'),
                'ONTOLOGY_VERTICE_REF',
                'COMPOUND_CHILD_ID',
                lambda t, s: s['VERTICE_REF'])

    # inject vertice refs
    apply_each_(compounds,
                chebi['vertice'].to_dict('records'),
                'ONTOLOGY_VERTICE_REF',
                'COMPOUND_CHILD_ID',
                lambda t, s: s['VERTICE_REF'])

    # Note that there are following types of relations:
    #
    # TYPE                          Count
    #
    # has_functional_parent         15702
    # has_parent_hydride             1597
    # has_part                       3416
    # has_role                      37858
    # is_a                         182476
    # is_conjugate_acid_of           7798
    # is_conjugate_base_of           7798
    # is_enantiomer_of               2458
    # is_substituent_group_from      1236
    # is_tautomer_of                 1680
    #
    # Among the relationships, is_conjugate_acid_of, and is_conjugate_base_of are identical,
    # is_enantiomer_of, is_tautomer_of are bi-directional.
    # The following is the (init id, final id) pair count table:
    #
    # TYPE                     Count
    # has_functional_parent       1
    # is_a                        1
    # is_conjugate_acid_of     7798
    # is_conjugate_base_of     7798
    # is_enantiomer_of         2458
    # is_tautomer_of           1680

    vert2onto = {x['ID']: x['COMPOUND_CHILD_ID']
                 for x in chebi['vertice'].to_dict('records')}
    ontology_relations = [{'TYPE': x['TYPE'].upper(),
                           'INIT_ID': vert2onto[x['INIT_ID']],
                           'FINAL_ID': vert2onto[x['FINAL_ID']],
                           'STATUS': x['STATUS']} for x in chebi['relation'].to_dict('records')]

    # add field PARENTS using relation 'IS_A'
    apply_each_(compounds,
                [e for e in ontology_relations if e['TYPE'] == 'IS_A'],
                'PARENTS',
                'FINAL_ID',
                lambda t, s: t.get('PARENTS', []) + [s['INIT_ID']])

    # construct field ANCESTORS
    for compound in compounds.values():
        add_ancestors_(compounds, compound)

    # extract REFERENCES
    # references = [{'ID': compound['ID'], 'REFERENCES': compound['REFERENCES']}
    #               for compound in compounds.values() if 'REFERENCES' in compound]
    for compound in compounds.values():
        compound.pop('REFERENCES', None)

    return {'compounds': list(compounds.values()),
            # 'references': references, # Too large to store in mongodb
            'ontology_relations': ontology_relations}
